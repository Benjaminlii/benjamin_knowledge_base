# Note Of Read Kafka Docs

## 1. 开始

### 1.1 引言

> https://kafka.apache.org/documentation/#introduction

#### 1.1.1什么是事件流?

事件流相当于数字版的人体中枢神经系统.

在未来, 业务将越来越多的由软件定义, 且自动化, 并且软件的用户也是软件.事件流是实现这一目标的技术基础.

从技术上讲, 事件流是实时的从事件源中捕获数据的一种实践, 存储这些数据供后续的检索, 实时地回顾性地对事件流进行操控、处理以及响应. 根据需要讲事件流路由到不同的目标技术中. 因此事件流保证了数据的连续流动和解析, 从而让正确的信息出现在正确的时间和正确的地点.

#### 1.1.2我们可以使用事件流来做什么?

事件流被广泛的应用与大量的行业和组织的各种各样的用例中. 举例:

1. 实时的处理支付和金融事务, 如股票交易、银行和保险业.
1. 实时的跟踪和监控汽车、车队以及货运, 如物流和汽车行业.
1. 持续的捕获和分析来自物联网设备或者其他设备中的传感器数据.
1. 收集并立即响应用户的活动以及指令.
1. 连接、存储和提供由公司不同部门产生的数据.
1. 是数据平台, 事件驱动架构以及微服务的基础.

#### 1.1.3Kafka是一个事件流平台, 意味着什么?

Kafka提供了三种能力来实现端到端的事件流用例:

1. 发布和订阅事件流
1. 持久并且可靠的存储事件流
1. 事件发生时或者回溯性的处理事件流

所有这些功能都以分布式, 可拓展, 伸缩, 容错, 安全的方式提供. Kafka可以部署在物理机, 虚拟机, 容器, 本机以及云中.你可以自己管理Kafka环境也可以使用提供商提供的完整托管服务.

#### 1.1.4Kafka是如何工作的

Kafka是服务端和客户端通过高性能TCP协议通信的一个分布式系统。可以部署在物理机, 虚拟机, 容器中。

服务端：Kafka作为集群运行, 可以扩越多个区域。其中一些服务构成存储层, 成为代理。其他的服务器运行Kafka connect, 通过事件流的形式导入导出数据, 从而将Kafka和现有的系统（如关系型数据库）集成。Kafka有高度可扩展行和容错性, 如何任何一个服务器出现错误, 其他的服务器会代替它工作。

客户端：允许你便携分布式的app和微服务, 在并行, 大规模和容错的方式读写和处理事件流。Kafka附带了一些客户端, 在java, scala的客户端中可以支持更高级的 Kafka Streams 库。还提供了go, python, c/c++等等编程语言的客户端以及REST API。

#### 1.1.5主要概念和术语

一个事件意味着你的业务中“有什么事情发生了”。这在文档中也被称为记录或者消息。当你在Kafka中读写数据时，你就用事件的形式做了这件事。概念上，一个事件包含键，值，时间戳和可选的元数据头。举例如下：

- 键：Alice
- 值：付200给Bob
- 时间戳：2022.1.25 14:06

生产者是发布时间到Kafka的这些客户端应用，消费者是订阅（读并且处理）这些事件的端。在Kafka中，生产者和消费者是完全解耦并且相互不感知的。这是Kafka实现总所周知的改读可拓展性的关键设计元素。举个例子，生产者从不需要等待消费者。Kafka提供了各种各样的保证，比如只处理一次事件的能力。

事件是有组织的并且持久的存储在主题（topic）中。非常简单，一个主题就是一个文件系统中的文件夹，事件则是这个文件夹中的文件。主题在Kafka中总是多生产者和多订阅的：一个主题可以有零至多个生产者想起中写入事件，也可以有零至多个消费者订阅这些事件。主题中的事件可以根据需要随时读取，这和传统消息系统不同，事件在在被消费后不会被删除。相反，你可以定义Kafka按照主题纬度定义保留你的事件多久，在此之后，旧的事件将会被丢弃。Kafka的性能在数据大小方面是有效恒定的，所以长时间的存储数据时完全没问题的。

主题是分段的，这意味着主题分布在不同Kafka代理的许多“桶”上。这种分布式的数据放置对可拓展性是非常重要的，因为这允许客户端应用同时在多个代理中读写数据。当新事件被发布到主题中时，实际上会被附加到这个主题的某个分区中。具有相同事件key的事件会被写入到同一个分区中，Kafka保证指定主题分区的多个消费者总是在用事件写入的顺序来读取该分区的事件。

![主题分区](https://kafka.apache.org/images/streams-and-tables-p1_p4.png)
上图：示例的主题有四个分区P1-P4，两个不同的生产者相互独立地通过网络向主题的分区中写入事件来发布新事件。这些事件拥有同样的key（图中按颜色表示）的会被写入到同一个分区中。两个生产者的事件也可以被写入同一个分区，只要key相同。

为了数据的容错性和高可用性，每一个主题都可以被复制，甚至跨越地理区域或者数据中心，所以总会有多个代理拥有拷贝的数据，以防止出现问题，你可以去维护代理等等。一个公用的生产设置是复制因子为3，也就是说，一份数据总会有三个副本。这种复制是在主题分区级别执行的。


