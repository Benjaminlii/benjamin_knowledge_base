# Note Of Read Kafka Docs

## 1. 开始

### 1.1 引言

> https://kafka.apache.org/documentation/#introduction

#### 1.1.1 什么是事件流?

事件流相当于数字版的人体中枢神经系统.

在未来, 业务将越来越多的由软件定义, 且自动化, 并且软件的用户也是软件.事件流是实现这一目标的技术基础.

从技术上讲, 事件流是实时的从事件源中捕获数据的一种实践, 存储这些数据供后续的检索, 实时地回顾性地对事件流进行操控、处理以及响应. 根据需要讲事件流路由到不同的目标技术中. 因此事件流保证了数据的连续流动和解析, 从而让正确的信息出现在正确的时间和正确的地点.

#### 1.1.2 我们可以使用事件流来做什么?

事件流被广泛的应用与大量的行业和组织的各种各样的用例中. 举例:

1. 实时的处理支付和金融事务, 如股票交易、银行和保险业.
1. 实时的跟踪和监控汽车、车队以及货运, 如物流和汽车行业.
1. 持续的捕获和分析来自物联网设备或者其他设备中的传感器数据.
1. 收集并立即响应用户的活动以及指令.
1. 连接、存储和提供由公司不同部门产生的数据.
1. 是数据平台, 事件驱动架构以及微服务的基础.

#### 1.1.3 Kafka是一个事件流平台, 意味着什么?

Kafka提供了三种能力来实现端到端的事件流用例:

1. 发布和订阅事件流
1. 持久并且可靠的存储事件流
1. 事件发生时或者回溯性的处理事件流

所有这些功能都以分布式, 可拓展, 伸缩, 容错, 安全的方式提供. Kafka可以部署在物理机, 虚拟机, 容器, 本机以及云中.你可以自己管理Kafka环境也可以使用提供商提供的完整托管服务.

#### 1.1.4 Kafka是如何工作的

Kafka是服务端和客户端通过高性能TCP协议通信的一个分布式系统。可以部署在物理机, 虚拟机, 容器中。

服务端：Kafka作为集群运行, 可以扩越多个区域。其中一些服务构成存储层, 成为代理。其他的服务器运行Kafka connect, 通过事件流的形式导入导出数据, 从而将Kafka和现有的系统（如关系型数据库）集成。Kafka有高度可扩展行和容错性, 如何任何一个服务器出现错误, 其他的服务器会代替它工作。

客户端：允许你便携分布式的app和微服务, 在并行, 大规模和容错的方式读写和处理事件流。Kafka附带了一些客户端, 在java, scala的客户端中可以支持更高级的 Kafka Streams 库。还提供了go, python, c/c++等等编程语言的客户端以及REST API。

#### 1.1.5 主要概念和术语

一个事件意味着你的业务中“有什么事情发生了”。这在文档中也被称为记录或者消息。当你在Kafka中读写数据时，你就用事件的形式做了这件事。概念上，一个事件包含键，值，时间戳和可选的元数据头。举例如下：

- 键：Alice
- 值：付200给Bob
- 时间戳：2022.1.25 14:06

生产者是发布时间到Kafka的这些客户端应用，消费者是订阅（读并且处理）这些事件的端。在Kafka中，生产者和消费者是完全解耦并且相互不感知的。这是Kafka实现总所周知的改读可拓展性的关键设计元素。举个例子，生产者从不需要等待消费者。Kafka提供了各种各样的保证，比如只处理一次事件的能力。

事件是有组织的并且持久的存储在主题（topic）中。非常简单，一个主题就是一个文件系统中的文件夹，事件则是这个文件夹中的文件。主题在Kafka中总是多生产者和多订阅的：一个主题可以有零至多个生产者想起中写入事件，也可以有零至多个消费者订阅这些事件。主题中的事件可以根据需要随时读取，这和传统消息系统不同，事件在在被消费后不会被删除。相反，你可以定义Kafka按照主题纬度定义保留你的事件多久，在此之后，旧的事件将会被丢弃。Kafka的性能在数据大小方面是有效恒定的，所以长时间的存储数据时完全没问题的。

主题是分段的，这意味着主题分布在不同Kafka代理的许多“桶”上。这种分布式的数据放置对可拓展性是非常重要的，因为这允许客户端应用同时在多个代理中读写数据。当新事件被发布到主题中时，实际上会被附加到这个主题的某个分区中。具有相同事件key的事件会被写入到同一个分区中，Kafka保证指定主题分区的多个消费者总是在用事件写入的顺序来读取该分区的事件。

![主题分区](https://kafka.apache.org/images/streams-and-tables-p1_p4.png)
上图：示例的主题有四个分区P1-P4，两个不同的生产者相互独立地通过网络向主题的分区中写入事件来发布新事件。这些事件拥有同样的key（图中按颜色表示）的会被写入到同一个分区中。两个生产者的事件也可以被写入同一个分区，只要key相同。

为了数据的容错性和高可用性，每一个主题都可以被复制，甚至跨越地理区域或者数据中心，所以总会有多个代理拥有拷贝的数据，以防止出现问题，你可以去维护代理等等。一个公用的生产设置是复制因子为3，也就是说，一份数据总会有三个副本。这种复制是在主题分区级别执行的。

#### 1.1.6 Kafka APIs

除了命令行工具之外，Kafka还为Java和Scala提供了5个核心API：
- 管理api用于管理和检查主题，代理和其他的Kafka实例。
- 生产者api用于向一个或者多个Kafka主题发布时间流消息。
- 消费者api用于订阅一至多个主题的消息并进行处理。
- Kafka流api实现流处理应用和微服务。它提供了高级方法来处理事件流，包括转换，操作状态（聚合和连接），窗口，基于事件时间的处理等等。从一至多个主题中读取输入，为一至多个主题生成输出。有效的实现输入输出的转换。
- Kafka连接api可以构建和运行可复用的导入导出连接器，这些连接器可以让外部系统或应用向生产者或者消费者中读写数据，从而让他们与Kafka集成。例如：一个连接到关系型数据库的连接器可以捕获对表的每一次更改。实际上并不需要实现自己的连接器，Kafka社区已经提供了非常多现成的连接器。

### 1.2 用例

以下是关于Kafka的一些流行用例：

#### 1.2.1 消息

Kafka可以非常好的替代传统的消息代理。使用消息代理的原因有很多（从数据生产者那里解耦消息的处理，缓存未处理的消息，等等）。相对于大多数的消息系统，Kafka拥有更好的吞吐量，内置的分区，复制和容错，这使得Kafka成为大规模数据处理应用的一个好的解决方案。
在我们的经验里，消息的使用通常是低吞吐量的，但可能会需要低的端到端延迟，并且通常依赖Kafka提供的强大的持久化保证。

在这个领域内kafka可以于传统的消息系统相媲美。

#### 1.2.2 网站活动跟踪

Kafka的原始用例是能够重构用户活动跟踪流程为一组实时的发布订阅数据源。这意味着网站活动（页面浏览，搜索或者其他用户可能的活动）会被发布到核心主题，每一个活动类型只有一个主题。这些数据源可以用于订阅一些用例，包括实时处理，实时监控，以及加载到Hadoop或者离线的数据仓库系统以供离线处理和报告。
活动跟踪的量通常非常大，每个用户页面都会生成很多活动消息。

#### 1.2.3 指标

Kafka常常被用来操作监控数据。这涉及到聚合来自分布式应用的统计信息，并生成集中式的操作数据源。

#### 1.2.4 日志聚合

很多人将Kafka作为日志聚合解决方案的替代品。日志聚合通常需要在服务器外收集原始日志文件，并且将它们上传到一个统一的位置（一个文件服务或者Hadoop分布式文件系统）去处理。Kafka抽离了文件细节，并且以更清晰的方式将日志或者事件数据抽象为一系列消息。这个允许更低延迟的处理、更容易支持的多数据源和分布式数据消费。相对比Scribe或者Flume这样的以日志为中心的系统，Kafka提供了同样好的性能，由于复制带来的更强大的持久化保证，更低的端到端延迟。

#### 1.2.5 流式处理

许多 Kafka 的用户使用由多个节点组成的处理流程来处理数据，从 Kafka 主题中消费原始数据，然后进行聚合，丰富，或者以其他方式转化为新的主题进一步被后续的流程处理。例如：一个推荐新文章的处理流程可能会从RSS源来爬取文章内容，然后将其发布到一个‘文章’的主题；进一步的处理可能是对这些内容规范化或者去重，然后发布这个净化后的文章内容到一个新的主题；最终的处理步骤可能是尝试将该内容推荐给用户。这样的处理流程创建了一个基于每一个主题的实时数据流向图。从0.10.0.0版本开始，Kafka 提供了一个名为 Kafka Streams 的轻量级但是强大的流处理库去处理类似上述的数据处理流程。除了 Kafka Streams, 其他的开源流处理工具还包括 Apache Storm 和 Apache Samza

#### 1.2.6 事件溯源

事件溯源是一种应用程序设计风格，状态的更新会被记录为时间顺序排列的记录。Kafka对非常大存储日志数据的支持使得它成为了以这种风格构建应用程序的杰出后端。

#### 1.2.7 提交日志

Kafka可以为分布式系统提供一种外部提交日志的服务。日志可以帮助复制节点之间的数据，然后用于失败节点重新同步数据的机制来帮助其恢复数据。Kafka日志压缩的特性可以帮助支持这种用法。在这个用法中，Kafka类似于Apache BookKeeper项目。

## 4. 设计

#### 4.1 动机

我们设计Kafka是为了能够以一个统一的平台去处理一个大公司可能拥有的全部数据源。为了做到这一点，我们需要思考非常广的用例。

它需要有高吞吐量去支持大容量的时间流，例如实时的日志聚合。

它需要优雅的处理巨量的数据积压，从而支持来自线下系统的周期性数据加载。

同时意味着系统需要处理低延迟的交付去处理更多传统的消息功能。

我们想要支持分区，分布式，实时处理这些数据源，以生成新的衍生数据。这促进了我们的分区和消费者模型。

最后在数据流向其他数据系统用来进行服务的情况下，我们知道系统可能需要能够在机器存在故障的情况下保证容错性。

支持这些用例让我们采用了一种具有很多独特元素的设计，对比传统消息系统更像一个数据库日志。
